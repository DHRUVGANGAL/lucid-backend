# Backend Lucid

**AI-Powered Requirements Analysis & Decision Engine**

An intelligent backend system that analyzes requirement documents, detects project context, generates architecture designs, estimates effort, and manages decisions with full audit trails.

---

## üéØ Overview

Backend Lucid is a decision intelligence platform that:
- **Parses** uploaded documents (PDF, DOCX, TXT)
- **Detects** context type (Initial Requirement vs Change Request)
- **Normalizes** requirements into structured format
- **Generates** architecture designs and impact analysis
- **Estimates** effort with historical bias correction
- **Stores** semantic memory for pattern recognition

---

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                           API Layer                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ
‚îÇ  ‚îÇ  Health  ‚îÇ  ‚îÇ Analyze-File ‚îÇ  ‚îÇ   Decisions    ‚îÇ                 ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     Decision Orchestrator                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Parser  ‚îÇ‚Üí ‚îÇ    Decision   ‚îÇ‚Üí ‚îÇ      Archestra Platform      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ Factory  ‚îÇ  ‚îÇ    Pipeline   ‚îÇ  ‚îÇ   (Context, Arch, Impact)    ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚ñº               ‚ñº               ‚ñº
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚îÇ PostgreSQL  ‚îÇ  ‚îÇ   Qdrant    ‚îÇ  ‚îÇ   Archestra  ‚îÇ
     ‚îÇ  (Primary)  ‚îÇ  ‚îÇ  (Vectors)  ‚îÇ  ‚îÇ  (AI Core)   ‚îÇ
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
## üöÄ How to Run

### Using Docker (Recommended)

1.  **Configure Environment**:
    Ensure your `.env` file has the `GEMINI_API_KEY` set.

2.  **Start Services**:
    ```bash
    docker-compose up --build -d
    ```

3.  **Access Interfaces**:
    - **Backend API Docs**: [http://localhost:8000/docs](http://localhost:8000/docs)
    - **Archestra UI**: [http://localhost:3000](http://localhost:3000)

4.  **Stop Services**:
    ```bash
    docker-compose down
    ```

---

## ü§ñ AI Architecture

We use **Archestra**, an enterprise-grade AI orchestration platform, to decouple AI logic from the backend.

### Why Archestra?
- **Separation of Concerns**: The FastAPI backend handles business logic and persistence, while Archestra manages LLM interactions, prompt engineering, and agent chaining.
- **Traceability**: Every definition, decision, and risk assessment is traceable through Archestra's audit logs.
- **Enterprise Readiness**: Archestra provides a robust runtime for agents with built-in retries, caching, and model gateway management.

### Multi-Agent Workflow
The `decision_pipeline` orchestrates a team of specialized agents:
1. **ParserAgent**: Extracts structured requirements.
2. **ContextAgent**: Determines project intent and risk.
3. **ArchitectureAgent**: Proposes high-level designs.
4. **ImpactAgent**: Analyzes technical and business impact.
5. **EstimationAgent**: Calculates effort and confidence.
6. **ExplanationAgent**: Synthesizes an executive summary.

---

## üìÅ Project Structure

```
app/
‚îú‚îÄ‚îÄ api/v1/
‚îÇ   ‚îú‚îÄ‚îÄ endpoints/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ health.py          # Health check
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analyze.py         # File analysis endpoint
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ decisions.py       # Decision CRUD & approval
‚îÇ   ‚îî‚îÄ‚îÄ router.py
‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îú‚îÄ‚îÄ requirement.py         # Requirements extraction
‚îÇ   ‚îú‚îÄ‚îÄ architecture.py        # Architecture design
‚îÇ   ‚îú‚îÄ‚îÄ impact.py              # Impact analysis
‚îÇ   ‚îú‚îÄ‚îÄ estimation.py          # Effort estimation
‚îÇ   ‚îî‚îÄ‚îÄ explanation.py         # Executive summary
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ orchestrator/          # Pipeline coordination
‚îÇ   ‚îú‚îÄ‚îÄ context/               # MCP read/write services
‚îÇ   ‚îú‚îÄ‚îÄ memory/                # Supermemory (Qdrant)
‚îÇ   ‚îú‚îÄ‚îÄ normalization/         # Document normalization
‚îÇ   ‚îú‚îÄ‚îÄ parser/                # PDF/DOCX/TXT parsing
‚îÇ   ‚îú‚îÄ‚îÄ rules/                 # Deterministic rule engine
‚îÇ   ‚îî‚îÄ‚îÄ decision/              # Approval & locking logic
‚îú‚îÄ‚îÄ models/                    # SQLAlchemy ORM models
‚îú‚îÄ‚îÄ db/
‚îÇ   ‚îú‚îÄ‚îÄ session.py             # Async DB session
‚îÇ   ‚îú‚îÄ‚îÄ repositories.py        # Data access layer
‚îÇ   ‚îî‚îÄ‚îÄ base.py                # Base model
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ config.py              # Settings (env vars)
‚îÇ   ‚îú‚îÄ‚îÄ logging.py             # Structured logging
‚îÇ   ‚îî‚îÄ‚îÄ llm/                   # LLM client & embeddings
‚îú‚îÄ‚îÄ middleware/
‚îÇ   ‚îî‚îÄ‚îÄ tracing.py             # Request ID tracing
‚îî‚îÄ‚îÄ main.py                    # FastAPI application
```

---

## üîå API Endpoints

### Health Check
```
GET /api/v1/health
Response: { "status": "healthy" }
```

### Analyze File
```
POST /api/v1/analyze-file
Content-Type: multipart/form-data

Parameters:
  - file: UploadFile (PDF, DOCX, TXT)
  - project_id: Optional[UUID] - Existing project
  - project_name: Optional[str] - New project name

Response:
{
  "project_id": "uuid",
  "decision_id": "uuid",
  "context_type": "initial_requirement | change_request",
  "confidence_score": 0.85,
  "risk_level": "low | medium | high | critical",
  "normalized_data": {...},
  "rule_results": {...},
  "requirements": {...},
  "architecture": {...},
  "impact": {...},
  "estimation": {...},
  "explanation": {...}
}
```

### Decision Management
```
GET    /api/v1/decisions/{id}          # Get decision
GET    /api/v1/decisions/{id}/status   # Get lock status
POST   /api/v1/decisions/{id}/submit   # Submit for review
POST   /api/v1/decisions/{id}/approve  # Approve (locks)
POST   /api/v1/decisions/{id}/lock     # Mark implemented
POST   /api/v1/decisions/{id}/reject   # Reject
PATCH  /api/v1/decisions/{id}          # Update (if unlocked)
```

---

## üîÑ Pipeline Flows

### Initial Requirement Flow
```
1. Parse Document
2. Detect Context ‚Üí INITIAL_REQUIREMENT
3. Create Project (if new)
4. Store Document in DB
5. Normalize Requirements
6. Apply Rule Engine
7. Run Agents:
   ‚îî‚îÄ‚îÄ Requirements ‚Üí Architecture ‚Üí Impact ‚Üí Estimation ‚Üí Explanation
8. Persist Architecture Baseline (ACTIVE)
9. Persist Decision (DRAFT)
10. Store in Supermemory
```

### Change Request Flow
```
1. Parse Document
2. Detect Context ‚Üí CHANGE_REQUEST
3. Fetch Existing Context (MCP)
   ‚îú‚îÄ‚îÄ Project context
   ‚îú‚îÄ‚îÄ Active baseline
   ‚îî‚îÄ‚îÄ Locked decisions
4. Store Document (additive)
5. Generate Proposed Architecture (INACTIVE)
6. Run Impact Diff (existing vs proposed)
7. Recall Supermemory ‚Üí Bias signals
8. Adjust Estimation (historical correction)
9. Persist Decision (linked to existing baseline)
10. Update Supermemory with patterns
```

---

## üß† Supermemory (Semantic Memory)

Vector-based memory layer using **Qdrant** + **Gemini Embeddings** (3072 dimensions).

**Store:**
```python
await memory.store(
    decision_id=uuid,
    project_id=uuid,
    summary="Decision summary text",
    risk_level=RiskLevel.MEDIUM,
    tags=["auth", "api"],
    estimated_hours=40
)
```

**Recall:**
```python
result = await memory.recall(
    query="authentication implementation",
    project_id=uuid,
    limit=10
)
# result.entries - matching decisions
# result.bias_signals - detected patterns
# result.patterns - common themes
```

**Bias Detection:**
| Signal | Condition |
|--------|-----------|
| `underestimation` | >50% of decisions exceeded estimate by >20% |
| `overestimation` | >50% of decisions completed <80% of estimate |
| `risk_concentration` | >30% of decisions are HIGH/CRITICAL |

---

## üìä Data Models

### Core Entities
- **Project** - Top-level container
- **RequirementDocument** - Uploaded files
- **NormalizedRequirement** - Extracted requirements
- **ArchitectureBaseline** - Versioned designs
- **Decision** - Analysis results with state
- **DeliveryOutcome** - Actual vs estimated metrics

### Decision States
```
DRAFT ‚Üí PENDING_REVIEW ‚Üí APPROVED ‚Üí IMPLEMENTED
                       ‚Üò REJECTED
```

**Locking Rules:**
- `APPROVED` and `IMPLEMENTED` are **locked**
- Locked decisions return `403 Forbidden` on modification
- All future changes must reference locked decisions

---

## ‚öôÔ∏è Configuration

Create `.env` file:
```env
# API
PROJECT_NAME=Backend-Lucid
API_V1_STR=/api/v1

# Database
DATABASE_URL=postgresql+asyncpg://user:pass@localhost:5432/lucid

# Gemini (Google AI)
GEMINI_API_KEY=your-gemini-api-key

# Qdrant
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION=supermemory

# LLM Provider
LLM_PROVIDER=gemini  # Default provider
```

---

## üöÄ Quick Start

```bash
# Install dependencies
pip install -r requirements.txt

# Start Qdrant (Docker)
docker run -p 6333:6333 qdrant/qdrant

# Start PostgreSQL
docker run -p 5432:5432 -e POSTGRES_PASSWORD=postgres postgres

# Run server
uvicorn app.main:app --reload
```

---

## üìã Dependencies

```
fastapi
uvicorn[standard]
pydantic-settings
sqlalchemy[asyncio]
asyncpg
google-generativeai
qdrant-client
python-docx
pypdf
structlog
python-multipart
python-dotenv
```

---

## üîç Structured Logging

All logs include `request_id` for tracing:
```json
{
  "event": "decision_created",
  "request_id": "a1b2c3d4",
  "decision_id": "uuid",
  "project_id": "uuid",
  "status": "draft",
  "timestamp": "2026-02-06T18:00:00Z"
}
```

Sensitive data (passwords, tokens, embeddings) is automatically **redacted**.

---

## üìù License

MIT
